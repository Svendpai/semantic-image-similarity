{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Similarity between two images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (59.5.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (1.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: six in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.20.3)\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "from keras.datasets import cifar100\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "x_validation shape: (5000, 32, 32, 3)\n",
      "x_test shape: (5000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "y_validation shape: (5000, 1)\n",
      "y_test shape: (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Split x_train in half and make x_validation\n",
    "x_validation = x_test[0:5000]\n",
    "x_test = x_test[5000:]\n",
    "y_validation = y_test[0:5000]\n",
    "y_test = y_test[5000:]\n",
    "\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert x_test.shape == (5000, 32, 32, 3)\n",
    "assert x_validation.shape == (5000, 32, 32, 3)\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_validation.shape == (5000, 1)\n",
    "assert y_test.shape == (5000, 1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_validation shape:', x_validation.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_validation shape:', y_validation.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: \"apple\",\n",
    "    1: \"aquarium_fish\",\n",
    "    2: \"baby\",\n",
    "    3: \"bear\",\n",
    "    4: \"beaver\",\n",
    "    5: \"bed\",\n",
    "    6: \"bee\",\n",
    "    7: \"beetle\",\n",
    "    8: \"bicycle\",\n",
    "    9: \"bottle\",\n",
    "    10: \"bowl\",\n",
    "    11: \"boy\",\n",
    "    12: \"bridge\",\n",
    "    13: \"bus\",\n",
    "    14: \"butterfly\",\n",
    "    15: \"camel\",\n",
    "    16: \"can\",\n",
    "    17: \"castle\",\n",
    "    18: \"caterpillar\",\n",
    "    19: \"cattle\",\n",
    "    20: \"chair\",\n",
    "    21: \"chimpanzee\",\n",
    "    22: \"clock\",\n",
    "    23: \"cloud\",\n",
    "    24: \"cockroach\",\n",
    "    25: \"couch\",\n",
    "    26: \"cra\",\n",
    "    27: \"crocodile\",\n",
    "    28: \"cup\",\n",
    "    29: \"dinosaur\",\n",
    "    30: \"dolphin\",\n",
    "    31: \"elephant\",\n",
    "    32: \"flatfish\",\n",
    "    33: \"forest\",\n",
    "    34: \"fox\",\n",
    "    35: \"girl\",\n",
    "    36: \"hamster\",\n",
    "    37: \"house\",\n",
    "    38: \"kangaroo\",\n",
    "    39: \"keyboard\",\n",
    "    40: \"lamp\",\n",
    "    41: \"lawn_mower\",\n",
    "    42: \"leopard\",\n",
    "    43: \"lion\",\n",
    "    44: \"lizard\",\n",
    "    45: \"lobster\",\n",
    "    46: \"man\",\n",
    "    47: \"maple_tree\",\n",
    "    48: \"motorcycle\",\n",
    "    49: \"mountain\",\n",
    "    50: \"mouse\",\n",
    "    51: \"mushroom\",\n",
    "    52: \"oak_tree\",\n",
    "    53: \"orange\",\n",
    "    54: \"orchid\",\n",
    "    55: \"otter\",\n",
    "    56: \"palm_tree\",\n",
    "    57: \"pear\",\n",
    "    58: \"pickup_truck\",\n",
    "    59: \"pine_tree\",\n",
    "    60: \"plain\",\n",
    "    61: \"plate\",\n",
    "    62: \"poppy\",\n",
    "    63: \"porcupine\",\n",
    "    64: \"possum\",\n",
    "    65: \"rabbit\",\n",
    "    66: \"raccoon\",\n",
    "    67: \"ray\",\n",
    "    68: \"road\",\n",
    "    69: \"rocket\",\n",
    "    70: \"rose\",\n",
    "    71: \"sea\",\n",
    "    72: \"seal\",\n",
    "    73: \"shark\",\n",
    "    74: \"shrew\",\n",
    "    75: \"skunk\",\n",
    "    76: \"skyscraper\",\n",
    "    77: \"snail\",\n",
    "    78: \"snake\",\n",
    "    79: \"spider\",\n",
    "    80: \"squirrel\",\n",
    "    81: \"streetcar\",\n",
    "    82: \"sunflower\",\n",
    "    83: \"sweet_pepper\",\n",
    "    84: \"table\",\n",
    "    85: \"tank\",\n",
    "    86: \"telephone\",\n",
    "    87: \"television\",\n",
    "    88: \"tiger\",\n",
    "    89: \"tractor\",\n",
    "    90: \"train\",\n",
    "    91: \"trout\",\n",
    "    92: \"tulip\",\n",
    "    93: \"turtle\",\n",
    "    94: \"wardrobe\",\n",
    "    95: \"whale\",\n",
    "    96: \"willow_tree\",\n",
    "    97: \"wolf\",\n",
    "    98: \"woman\",\n",
    "    99: \"worm\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess dataset\n",
    "\n",
    "\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(x):\n",
    "\t# convert from integers to floats\n",
    "\tx_norm = x.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\tx_norm = x_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn x_norm\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=classes.__len__())\n",
    "y_validation = to_categorical(y_validation, num_classes=classes.__len__())\n",
    "y_test = to_categorical(y_test, num_classes=classes.__len__())\n",
    "\n",
    "x_train = prep_pixels(x_train)\n",
    "x_validation = prep_pixels(x_validation)\n",
    "x_test = prep_pixels(x_test)\n",
    "\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 6, 6, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 4, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               25700     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 444,036\n",
      "Trainable params: 444,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 19s 23ms/step - loss: 4.4920 - accuracy: 0.0201 - val_loss: 4.1853 - val_accuracy: 0.0500\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 4.0300 - accuracy: 0.0696 - val_loss: 3.7374 - val_accuracy: 0.1230\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 3.7212 - accuracy: 0.1222 - val_loss: 3.4603 - val_accuracy: 0.1818\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 3.5025 - accuracy: 0.1554 - val_loss: 3.2564 - val_accuracy: 0.2136\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 3.3446 - accuracy: 0.1872 - val_loss: 3.0602 - val_accuracy: 0.2558\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 3.2208 - accuracy: 0.2100 - val_loss: 2.9814 - val_accuracy: 0.2654\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 3.1206 - accuracy: 0.2301 - val_loss: 2.8636 - val_accuracy: 0.2850\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 3.0285 - accuracy: 0.2492 - val_loss: 2.7834 - val_accuracy: 0.2964\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 2.9459 - accuracy: 0.2638 - val_loss: 2.7159 - val_accuracy: 0.3176\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 2.8835 - accuracy: 0.2750 - val_loss: 2.6777 - val_accuracy: 0.3282\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes.__len__(), activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_validation, y_validation), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# save model\n",
    "model.save('./model/similarity_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export as tensorflow.js model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model as tensorflow.js model\n",
    "\n",
    "!tensorflowjs_converter --input_format=keras ./model/similarity_model.h5 ./model/tfjs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.326\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('%.3f' % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot diagnostic learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tfig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\tax[0].set_title('Cross Entropy Loss')\n",
    "\tax[0].set_xlabel('Epoch')\n",
    "\tax[0].set_ylabel('Loss')\n",
    "\tax[0].plot(history.history['loss'], color='blue', label='train')\n",
    "\tax[0].plot(history.history['val_loss'], color='orange', label='validation')\n",
    "\tax[0].legend()\n",
    "\n",
    "\t# plot accuracy\n",
    "\tax[1].set_title('Classification Accuracy')\n",
    "\tax[1].set_xlabel('Epoch')\n",
    "\tax[1].set_ylabel('Accuracy')\n",
    "\tax[1].plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tax[1].plot(history.history['val_accuracy'], color='orange', label='validation')\n",
    "\tax[1].legend()\n",
    "\t\n",
    "\tplt.show()\n",
    "\n",
    "summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data outside of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kappa Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "\n",
    "kappa = calculate_kappa(old_y_test, pred)\n",
    "print(\"Kappa: \", kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns confusion matrix\n",
    "\n",
    "cm = confusion_matrix(old_y_test, pred)\n",
    "\n",
    "cm = cm / cm.astype(float).sum(axis=1) # This line normalizes the calculated confusion matrix\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Convert to tflite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model('./model/similarity_model.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.experimental_new_converter = True\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95bedf10bfb8ab76b52888e4286a107c64e826336c41c64851a50835c33f2a43"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
