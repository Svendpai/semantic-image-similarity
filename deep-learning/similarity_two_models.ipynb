{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (59.5.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (1.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\svendpai\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Resizing\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "1.0\n",
      "0.0\n",
      "255.0\n"
     ]
    }
   ],
   "source": [
    "def normalize_pixels(image):\n",
    "    \"\"\"normalize pixels to be between 0 and 1\"\"\"\n",
    "\n",
    "\t# convert from integers to floats\n",
    "    image_norm = image.astype('float32')\n",
    "\t# normalize to range -1 and 1\n",
    "    image_norm = (image_norm - 127.5) / 127.5\n",
    "\n",
    "\t# return normalized images\n",
    "    return image_norm\n",
    "\n",
    "def de_normalize_pixels(image, _from = 0, _to = 1):\n",
    "    \"\"\"de-normalize pixels to be between 0 and 255\"\"\"\n",
    "\n",
    "    # Normalize between 0 and 1\n",
    "    image_de_norm = (image * 127.5) + 127.5\n",
    "\n",
    "    # Normalize between 0 and 1\n",
    "    image_de_norm = image_de_norm/255 \n",
    "\n",
    "    # Normalize between _from and _to\n",
    "    image_de_norm = (image_de_norm * (_to - _from)) + _from\n",
    "    \n",
    "    return image_de_norm\n",
    "\n",
    "def load_image(path):\n",
    "    \"\"\"load image from path and convert to array\"\"\"\n",
    "\n",
    "    img = load_img(path, target_size=(224, 224), interpolation='bilinear')\n",
    "    x = img_to_array(img)\n",
    "    x = normalize_pixels(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return x\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    \"\"\"shuffle two arrays in unison\"\"\"\n",
    "\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "test_image_1 = load_image(r'./data/dataset/all_souls/all_souls_000002.jpg')\n",
    "test_image_1_de = de_normalize_pixels(test_image_1, 0, 255)\n",
    "print(np.min(test_image_1))\n",
    "print(np.max(test_image_1))\n",
    "print(np.min(test_image_1_de))\n",
    "print(np.max(test_image_1_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "DATA_PATH = './data/dataset'\n",
    "DATA_TRAIN_SPLIT = 0.8\n",
    "DATA_VALIDATION_SPLIT = 0.1\n",
    "# The TEST split will be the remaining of the two splits\n",
    "\n",
    "#amount_of_positive_pairs_per_class = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of images: 555\n"
     ]
    }
   ],
   "source": [
    "# Load images into arrays\n",
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(DATA_PATH)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')) + list(data_dir.glob('*/*.jpeg')) + list(data_dir.glob('*/*.png')))\n",
    "print(\"Total amount of images: \" + str(image_count))\n",
    "\n",
    "folders = [x for x in data_dir.iterdir() if x.is_dir()]\n",
    "\n",
    "img_array_data = []\n",
    "\n",
    "for i, folder in enumerate(folders):\n",
    "    img_array_data.append([])\n",
    "\n",
    "    for j, img in enumerate(folder.iterdir()):\n",
    "        img_array_data[i].append(load_image(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Create image pairs\n",
    "def create_image_pairs(images):\n",
    "    for i, array in enumerate(images):\n",
    "        for j in range(len(array)):\n",
    "            # True\n",
    "            data.append([\n",
    "                images[i][j], \n",
    "                images[i][np.random.randint(0, len(images[i]) - 1)]])\n",
    "            labels.append(1)\n",
    "\n",
    "            x_1 = np.random.randint(0, len(images) - 1)\n",
    "            x_2 = np.random.randint(0, len(images[x_1]) - 1)\n",
    "\n",
    "            # False\n",
    "            data.append([\n",
    "                images[i][j], \n",
    "                images[x_1][x_2]])\n",
    "            labels.append(0)\n",
    "\n",
    "create_image_pairs(img_array_data)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[[ 0.11372549  0.39607844  0.6862745 ]\n",
      "     [ 0.11372549  0.39607844  0.6862745 ]\n",
      "     [ 0.11372549  0.40392157  0.6862745 ]\n",
      "     ...\n",
      "     [ 0.21568628  0.4509804   0.6784314 ]\n",
      "     [ 0.21568628  0.4509804   0.6784314 ]\n",
      "     [ 0.22352941  0.44313726  0.67058825]]\n",
      "\n",
      "    [[ 0.11372549  0.40392157  0.6862745 ]\n",
      "     [ 0.12156863  0.4117647   0.6862745 ]\n",
      "     [ 0.11372549  0.40392157  0.69411767]\n",
      "     ...\n",
      "     [ 0.21568628  0.4509804   0.6784314 ]\n",
      "     [ 0.21568628  0.4509804   0.6784314 ]\n",
      "     [ 0.20784314  0.4509804   0.6784314 ]]\n",
      "\n",
      "    [[ 0.12156863  0.4117647   0.6862745 ]\n",
      "     [ 0.12156863  0.4117647   0.6862745 ]\n",
      "     [ 0.12156863  0.4117647   0.69411767]\n",
      "     ...\n",
      "     [ 0.23137255  0.4509804   0.6784314 ]\n",
      "     [ 0.21568628  0.4509804   0.6784314 ]\n",
      "     [ 0.2         0.45882353  0.6784314 ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.8980392  -0.88235295 -0.88235295]\n",
      "     [-0.827451   -0.827451   -0.8509804 ]\n",
      "     [-0.7882353  -0.7882353  -0.8117647 ]\n",
      "     ...\n",
      "     [-0.88235295 -0.88235295 -0.8980392 ]\n",
      "     [-0.8901961  -0.88235295 -0.9137255 ]\n",
      "     [-0.8901961  -0.88235295 -0.9137255 ]]\n",
      "\n",
      "    [[-0.90588236 -0.8745098  -0.8745098 ]\n",
      "     [-0.8901961  -0.8745098  -0.8745098 ]\n",
      "     [-0.88235295 -0.8666667  -0.8745098 ]\n",
      "     ...\n",
      "     [-0.88235295 -0.8745098  -0.90588236]\n",
      "     [-0.88235295 -0.8745098  -0.8980392 ]\n",
      "     [-0.8980392  -0.88235295 -0.9137255 ]]\n",
      "\n",
      "    [[-0.90588236 -0.8745098  -0.8666667 ]\n",
      "     [-0.92156863 -0.8666667  -0.8666667 ]\n",
      "     [-0.9137255  -0.8666667  -0.85882354]\n",
      "     ...\n",
      "     [-0.88235295 -0.8745098  -0.8980392 ]\n",
      "     [-0.8901961  -0.88235295 -0.9137255 ]\n",
      "     [-0.8901961  -0.88235295 -0.9137255 ]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 0.84313726  0.8509804   0.8901961 ]\n",
      "     [ 0.8352941   0.85882354  0.8980392 ]\n",
      "     [ 0.8039216   0.8509804   0.90588236]\n",
      "     ...\n",
      "     [ 0.5294118   0.7019608   0.88235295]\n",
      "     [ 0.5294118   0.7019608   0.8901961 ]\n",
      "     [ 0.52156866  0.7019608   0.88235295]]\n",
      "\n",
      "    [[ 0.8509804   0.8666667   0.90588236]\n",
      "     [ 0.8352941   0.8745098   0.9137255 ]\n",
      "     [ 0.78039217  0.85882354  0.92156863]\n",
      "     ...\n",
      "     [ 0.5058824   0.7019608   0.88235295]\n",
      "     [ 0.5058824   0.69411767  0.88235295]\n",
      "     [ 0.5058824   0.7019608   0.8745098 ]]\n",
      "\n",
      "    [[ 0.8352941   0.8666667   0.90588236]\n",
      "     [ 0.81960785  0.8745098   0.92156863]\n",
      "     [ 0.7647059   0.85882354  0.92941177]\n",
      "     ...\n",
      "     [ 0.49803922  0.6862745   0.8745098 ]\n",
      "     [ 0.49803922  0.69411767  0.8745098 ]\n",
      "     [ 0.49803922  0.69411767  0.8745098 ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.49803922 -0.46666667 -0.73333335]\n",
      "     [-0.49019608 -0.4509804  -0.7176471 ]\n",
      "     [-0.49019608 -0.46666667 -0.73333335]\n",
      "     ...\n",
      "     [-0.6784314  -0.6784314  -0.67058825]\n",
      "     [-0.69411767 -0.67058825 -0.67058825]\n",
      "     [-0.6784314  -0.67058825 -0.67058825]]\n",
      "\n",
      "    [[-0.49019608 -0.46666667 -0.73333335]\n",
      "     [-0.52156866 -0.4745098  -0.7490196 ]\n",
      "     [-0.5294118  -0.49019608 -0.7411765 ]\n",
      "     ...\n",
      "     [-0.67058825 -0.6627451  -0.654902  ]\n",
      "     [-0.7019608  -0.7019608  -0.69411767]\n",
      "     [-0.7176471  -0.69411767 -0.6862745 ]]\n",
      "\n",
      "    [[-0.4745098  -0.4509804  -0.69411767]\n",
      "     [-0.5294118  -0.49019608 -0.7176471 ]\n",
      "     [-0.5372549  -0.49803922 -0.7490196 ]\n",
      "     ...\n",
      "     [-0.69411767 -0.6862745  -0.6784314 ]\n",
      "     [-0.70980394 -0.69411767 -0.6784314 ]\n",
      "     [-0.73333335 -0.6627451  -0.6627451 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[-0.01176471  0.22352941  0.45882353]\n",
      "     [-0.01176471  0.24705882  0.48235294]\n",
      "     [ 0.00392157  0.2627451   0.52156866]\n",
      "     ...\n",
      "     [ 0.12941177  0.37254903  0.58431375]\n",
      "     [ 0.11372549  0.35686275  0.5764706 ]\n",
      "     [ 0.09803922  0.34901962  0.56078434]]\n",
      "\n",
      "    [[-0.01960784  0.24705882  0.49803922]\n",
      "     [ 0.00392157  0.2627451   0.5137255 ]\n",
      "     [ 0.01176471  0.28627452  0.5294118 ]\n",
      "     ...\n",
      "     [ 0.15294118  0.39607844  0.60784316]\n",
      "     [ 0.12156863  0.38039216  0.5921569 ]\n",
      "     [ 0.10588235  0.3647059   0.5764706 ]]\n",
      "\n",
      "    [[ 0.00392157  0.2627451   0.52156866]\n",
      "     [ 0.00392157  0.28627452  0.5294118 ]\n",
      "     [ 0.01960784  0.29411766  0.54509807]\n",
      "     ...\n",
      "     [ 0.18431373  0.41960785  0.6313726 ]\n",
      "     [ 0.14509805  0.3882353   0.60784316]\n",
      "     [ 0.12156863  0.38039216  0.5921569 ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[ 0.33333334  0.3882353   0.44313726]\n",
      "     [-0.13725491 -0.00392157  0.09019608]\n",
      "     [-0.5921569  -0.5372549  -0.46666667]\n",
      "     ...\n",
      "     [-0.9372549  -0.92941177 -0.9372549 ]\n",
      "     [-0.94509804 -0.94509804 -0.94509804]\n",
      "     [-0.9529412  -0.94509804 -0.9529412 ]]\n",
      "\n",
      "    [[ 0.15294118  0.18431373  0.25490198]\n",
      "     [-0.43529412 -0.30980393 -0.2627451 ]\n",
      "     [-0.8352941  -0.8039216  -0.79607844]\n",
      "     ...\n",
      "     [-0.92941177 -0.92156863 -0.92941177]\n",
      "     [-0.90588236 -0.90588236 -0.92156863]\n",
      "     [-0.9372549  -0.9372549  -0.9372549 ]]\n",
      "\n",
      "    [[-0.4745098  -0.43529412 -0.31764707]\n",
      "     [-0.5921569  -0.5294118  -0.5058824 ]\n",
      "     [-0.81960785 -0.77254903 -0.78039217]\n",
      "     ...\n",
      "     [-0.9137255  -0.90588236 -0.92156863]\n",
      "     [-0.8980392  -0.8666667  -0.8980392 ]\n",
      "     [-0.8745098  -0.85882354 -0.88235295]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[-0.69411767 -0.73333335 -0.7411765 ]\n",
      "     [-0.75686276 -0.78039217 -0.78039217]\n",
      "     [-0.77254903 -0.8117647  -0.7647059 ]\n",
      "     ...\n",
      "     [-0.4117647  -0.34117648 -0.35686275]\n",
      "     [-0.5764706  -0.52156866 -0.54509807]\n",
      "     [-0.5764706  -0.56078434 -0.60784316]]\n",
      "\n",
      "    [[-0.70980394 -0.7490196  -0.7490196 ]\n",
      "     [-0.7176471  -0.77254903 -0.78039217]\n",
      "     [-0.7254902  -0.7882353  -0.7647059 ]\n",
      "     ...\n",
      "     [-0.6627451  -0.58431375 -0.73333335]\n",
      "     [-0.6        -0.54509807 -0.6862745 ]\n",
      "     [-0.60784316 -0.56078434 -0.69411767]]\n",
      "\n",
      "    [[-0.73333335 -0.78039217 -0.75686276]\n",
      "     [-0.70980394 -0.77254903 -0.75686276]\n",
      "     [-0.7647059  -0.8039216  -0.8117647 ]\n",
      "     ...\n",
      "     [-0.6784314  -0.58431375 -0.75686276]\n",
      "     [-0.67058825 -0.5764706  -0.77254903]\n",
      "     [-0.6313726  -0.5686275  -0.73333335]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.5529412  -0.52156866 -0.75686276]\n",
      "     [-0.49803922 -0.44313726 -0.73333335]\n",
      "     [-0.38039216 -0.3019608  -0.69411767]\n",
      "     ...\n",
      "     [-0.5686275  -0.5137255  -0.67058825]\n",
      "     [-0.5764706  -0.5294118  -0.69411767]\n",
      "     [-0.58431375 -0.5137255  -0.7254902 ]]\n",
      "\n",
      "    [[-0.16862746 -0.16862746 -0.4745098 ]\n",
      "     [-0.23137255 -0.18431373 -0.5294118 ]\n",
      "     [-0.30980393 -0.24705882 -0.654902  ]\n",
      "     ...\n",
      "     [-0.5764706  -0.5294118  -0.6862745 ]\n",
      "     [-0.6156863  -0.5686275  -0.70980394]\n",
      "     [-0.6        -0.54509807 -0.7019608 ]]\n",
      "\n",
      "    [[-0.23137255 -0.19215687 -0.43529412]\n",
      "     [-0.3019608  -0.24705882 -0.5921569 ]\n",
      "     [-0.27058825 -0.20784314 -0.5686275 ]\n",
      "     ...\n",
      "     [-0.5921569  -0.5921569  -0.69411767]\n",
      "     [-0.67058825 -0.6627451  -0.7411765 ]\n",
      "     [-0.6627451  -0.6313726  -0.7019608 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[-0.94509804 -0.94509804 -0.94509804]\n",
      "     [-0.94509804 -0.94509804 -0.94509804]\n",
      "     [-0.9529412  -0.9529412  -0.9529412 ]\n",
      "     ...\n",
      "     [-0.9764706  -0.9764706  -0.9764706 ]\n",
      "     [-0.9764706  -0.9764706  -0.9764706 ]\n",
      "     [-0.9764706  -0.9764706  -0.9764706 ]]\n",
      "\n",
      "    [[-0.94509804 -0.94509804 -0.94509804]\n",
      "     [-0.94509804 -0.94509804 -0.94509804]\n",
      "     [-0.94509804 -0.94509804 -0.94509804]\n",
      "     ...\n",
      "     [-0.96862745 -0.96862745 -0.96862745]\n",
      "     [-0.9764706  -0.9764706  -0.9764706 ]\n",
      "     [-0.96862745 -0.96862745 -0.96862745]]\n",
      "\n",
      "    [[-0.94509804 -0.94509804 -0.94509804]\n",
      "     [-0.94509804 -0.94509804 -0.94509804]\n",
      "     [-0.94509804 -0.94509804 -0.94509804]\n",
      "     ...\n",
      "     [-0.96862745 -0.96862745 -0.9764706 ]\n",
      "     [-0.96862745 -0.96862745 -0.96862745]\n",
      "     [-0.96862745 -0.96862745 -0.96862745]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.8745098  -0.8745098  -0.8901961 ]\n",
      "     [-0.88235295 -0.88235295 -0.8980392 ]\n",
      "     [-0.88235295 -0.88235295 -0.90588236]\n",
      "     ...\n",
      "     [-0.64705884 -0.6627451  -0.75686276]\n",
      "     [-0.64705884 -0.6627451  -0.75686276]\n",
      "     [-0.6627451  -0.6784314  -0.77254903]]\n",
      "\n",
      "    [[-0.8901961  -0.8901961  -0.90588236]\n",
      "     [-0.88235295 -0.88235295 -0.8980392 ]\n",
      "     [-0.8745098  -0.8745098  -0.8980392 ]\n",
      "     ...\n",
      "     [-0.62352943 -0.62352943 -0.70980394]\n",
      "     [-0.62352943 -0.6313726  -0.7176471 ]\n",
      "     [-0.6156863  -0.6392157  -0.7176471 ]]\n",
      "\n",
      "    [[-0.8901961  -0.8901961  -0.90588236]\n",
      "     [-0.8901961  -0.8901961  -0.90588236]\n",
      "     [-0.88235295 -0.88235295 -0.8980392 ]\n",
      "     ...\n",
      "     [-0.5294118  -0.52156866 -0.6313726 ]\n",
      "     [-0.52156866 -0.5294118  -0.6313726 ]\n",
      "     [-0.5058824  -0.5372549  -0.6313726 ]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 0.4117647   0.5294118   0.8509804 ]\n",
      "     [ 0.41960785  0.5372549   0.8745098 ]\n",
      "     [ 0.41960785  0.5294118   0.8745098 ]\n",
      "     ...\n",
      "     [-0.37254903 -0.6156863  -0.8509804 ]\n",
      "     [-0.4509804  -0.69411767 -0.88235295]\n",
      "     [-0.5058824  -0.69411767 -0.8745098 ]]\n",
      "\n",
      "    [[ 0.4117647   0.5294118   0.85882354]\n",
      "     [ 0.4117647   0.5372549   0.8745098 ]\n",
      "     [ 0.41960785  0.5372549   0.8745098 ]\n",
      "     ...\n",
      "     [-0.43529412 -0.6313726  -0.85882354]\n",
      "     [-0.4117647  -0.64705884 -0.85882354]\n",
      "     [-0.5686275  -0.7411765  -0.8980392 ]]\n",
      "\n",
      "    [[ 0.4117647   0.5294118   0.8666667 ]\n",
      "     [ 0.40392157  0.5372549   0.8745098 ]\n",
      "     [ 0.41960785  0.5372549   0.8745098 ]\n",
      "     ...\n",
      "     [-0.4745098  -0.6627451  -0.85882354]\n",
      "     [-0.3882353  -0.62352943 -0.84313726]\n",
      "     [-0.5058824  -0.7254902  -0.8901961 ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.654902   -0.4745098  -0.88235295]\n",
      "     [-0.654902   -0.48235294 -0.90588236]\n",
      "     [-0.654902   -0.48235294 -0.9137255 ]\n",
      "     ...\n",
      "     [ 0.2784314   0.30980393 -0.79607844]\n",
      "     [ 0.2784314   0.30980393 -0.78039217]\n",
      "     [ 0.2627451   0.30980393 -0.7411765 ]]\n",
      "\n",
      "    [[-0.28627452 -0.13725491 -0.8117647 ]\n",
      "     [-0.31764707 -0.14509805 -0.8117647 ]\n",
      "     [-0.31764707 -0.12941177 -0.79607844]\n",
      "     ...\n",
      "     [ 0.27058825  0.31764707 -0.8980392 ]\n",
      "     [ 0.2784314   0.3254902  -0.88235295]\n",
      "     [ 0.2784314   0.31764707 -0.88235295]]\n",
      "\n",
      "    [[ 0.09803922  0.19215687 -0.6       ]\n",
      "     [ 0.11372549  0.21568628 -0.6392157 ]\n",
      "     [ 0.13725491  0.22352941 -0.6313726 ]\n",
      "     ...\n",
      "     [ 0.24705882  0.29411766 -0.79607844]\n",
      "     [ 0.2627451   0.3019608  -0.79607844]\n",
      "     [ 0.27058825  0.31764707 -0.7882353 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[ 0.6784314   0.6627451   0.70980394]\n",
      "     [ 0.6784314   0.67058825  0.7254902 ]\n",
      "     [ 0.54509807  0.5529412   0.67058825]\n",
      "     ...\n",
      "     [-0.5372549  -0.48235294 -0.23137255]\n",
      "     [-0.56078434 -0.5137255  -0.21568628]\n",
      "     [-0.58431375 -0.52156866 -0.23137255]]\n",
      "\n",
      "    [[ 0.6862745   0.67058825  0.69411767]\n",
      "     [ 0.69411767  0.6862745   0.70980394]\n",
      "     [ 0.5686275   0.5921569   0.6627451 ]\n",
      "     ...\n",
      "     [-0.5372549  -0.49019608 -0.20784314]\n",
      "     [-0.52156866 -0.5058824  -0.23137255]\n",
      "     [-0.54509807 -0.5058824  -0.25490198]]\n",
      "\n",
      "    [[ 0.7254902   0.7176471   0.7254902 ]\n",
      "     [ 0.6784314   0.6784314   0.6862745 ]\n",
      "     [ 0.58431375  0.5764706   0.6392157 ]\n",
      "     ...\n",
      "     [-0.5137255  -0.46666667 -0.22352941]\n",
      "     [-0.52156866 -0.48235294 -0.23921569]\n",
      "     [-0.54509807 -0.49803922 -0.23921569]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.8117647  -0.8039216  -0.84313726]\n",
      "     [-0.8117647  -0.8039216  -0.8509804 ]\n",
      "     [-0.8117647  -0.8039216  -0.85882354]\n",
      "     ...\n",
      "     [-0.7882353  -0.78039217 -0.85882354]\n",
      "     [-0.7882353  -0.78039217 -0.85882354]\n",
      "     [-0.79607844 -0.78039217 -0.85882354]]\n",
      "\n",
      "    [[-0.827451   -0.81960785 -0.8509804 ]\n",
      "     [-0.81960785 -0.8117647  -0.8509804 ]\n",
      "     [-0.8117647  -0.8039216  -0.8509804 ]\n",
      "     ...\n",
      "     [-0.7882353  -0.77254903 -0.8745098 ]\n",
      "     [-0.79607844 -0.7882353  -0.84313726]\n",
      "     [-0.7882353  -0.78039217 -0.8509804 ]]\n",
      "\n",
      "    [[-0.81960785 -0.8117647  -0.85882354]\n",
      "     [-0.81960785 -0.8117647  -0.8509804 ]\n",
      "     [-0.8117647  -0.8039216  -0.8509804 ]\n",
      "     ...\n",
      "     [-0.78039217 -0.75686276 -0.85882354]\n",
      "     [-0.78039217 -0.7647059  -0.8509804 ]\n",
      "     [-0.78039217 -0.7647059  -0.84313726]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]\n",
      "     ...\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]]\n",
      "\n",
      "    [[ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]\n",
      "     ...\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]]\n",
      "\n",
      "    [[ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]\n",
      "     ...\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.44313726 -0.5058824  -0.56078434]\n",
      "     [-0.38039216 -0.49019608 -0.5137255 ]\n",
      "     [-0.23921569 -0.3882353  -0.38039216]\n",
      "     ...\n",
      "     [-0.3254902  -0.2        -0.654902  ]\n",
      "     [-0.35686275 -0.2        -0.6627451 ]\n",
      "     [-0.3647059  -0.19215687 -0.6784314 ]]\n",
      "\n",
      "    [[-0.40392157 -0.46666667 -0.54509807]\n",
      "     [-0.43529412 -0.48235294 -0.5686275 ]\n",
      "     [-0.41960785 -0.52156866 -0.5372549 ]\n",
      "     ...\n",
      "     [-0.33333334 -0.18431373 -0.654902  ]\n",
      "     [-0.35686275 -0.18431373 -0.64705884]\n",
      "     [-0.3647059  -0.19215687 -0.64705884]]\n",
      "\n",
      "    [[-0.3647059  -0.4509804  -0.5529412 ]\n",
      "     [-0.34901962 -0.44313726 -0.5529412 ]\n",
      "     [-0.41960785 -0.48235294 -0.5686275 ]\n",
      "     ...\n",
      "     [-0.31764707 -0.16078432 -0.6313726 ]\n",
      "     [-0.33333334 -0.1764706  -0.64705884]\n",
      "     [-0.33333334 -0.18431373 -0.654902  ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[ 0.8039216   0.8039216   0.8039216 ]\n",
      "     [ 0.81960785  0.81960785  0.81960785]\n",
      "     [ 0.8352941   0.8352941   0.8352941 ]\n",
      "     ...\n",
      "     [ 0.13725491  0.20784314  0.2627451 ]\n",
      "     [ 0.14509805  0.2         0.2627451 ]\n",
      "     [ 0.16862746  0.19215687  0.23921569]]\n",
      "\n",
      "    [[ 0.8117647   0.8117647   0.8117647 ]\n",
      "     [ 0.8352941   0.8352941   0.8352941 ]\n",
      "     [ 0.8509804   0.8509804   0.8509804 ]\n",
      "     ...\n",
      "     [ 0.14509805  0.20784314  0.27058825]\n",
      "     [ 0.14509805  0.20784314  0.27058825]\n",
      "     [ 0.16078432  0.20784314  0.25490198]]\n",
      "\n",
      "    [[ 0.84313726  0.84313726  0.84313726]\n",
      "     [ 0.85882354  0.85882354  0.85882354]\n",
      "     [ 0.8666667   0.8666667   0.8666667 ]\n",
      "     ...\n",
      "     [ 0.16078432  0.21568628  0.2784314 ]\n",
      "     [ 0.15294118  0.20784314  0.27058825]\n",
      "     [ 0.16862746  0.20784314  0.25490198]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.49019608 -0.41960785 -0.81960785]\n",
      "     [-0.4745098  -0.4117647  -0.8039216 ]\n",
      "     [-0.4745098  -0.40392157 -0.8117647 ]\n",
      "     ...\n",
      "     [-0.3882353  -0.34901962 -0.6156863 ]\n",
      "     [-0.39607844 -0.35686275 -0.60784316]\n",
      "     [-0.3882353  -0.3647059  -0.6156863 ]]\n",
      "\n",
      "    [[-0.4745098  -0.4117647  -0.8352941 ]\n",
      "     [-0.46666667 -0.40392157 -0.827451  ]\n",
      "     [-0.4745098  -0.40392157 -0.84313726]\n",
      "     ...\n",
      "     [-0.42745098 -0.3647059  -0.7254902 ]\n",
      "     [-0.42745098 -0.3647059  -0.69411767]\n",
      "     [-0.41960785 -0.3647059  -0.69411767]]\n",
      "\n",
      "    [[-0.4745098  -0.44313726 -0.8117647 ]\n",
      "     [-0.48235294 -0.44313726 -0.8117647 ]\n",
      "     [-0.49803922 -0.44313726 -0.81960785]\n",
      "     ...\n",
      "     [-0.4509804  -0.40392157 -0.7254902 ]\n",
      "     [-0.45882353 -0.4117647  -0.7254902 ]\n",
      "     [-0.46666667 -0.4117647  -0.7254902 ]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[-0.23137255  0.11372549  0.41960785]\n",
      "     [-0.23137255  0.11372549  0.41960785]\n",
      "     [-0.23137255  0.12156863  0.4117647 ]\n",
      "     ...\n",
      "     [-0.30980393  0.03529412  0.34117648]\n",
      "     [-0.3254902   0.02745098  0.33333334]\n",
      "     [-0.33333334  0.01960784  0.3254902 ]]\n",
      "\n",
      "    [[-0.23137255  0.11372549  0.4117647 ]\n",
      "     [-0.22352941  0.12156863  0.41960785]\n",
      "     [-0.22352941  0.12941177  0.4117647 ]\n",
      "     ...\n",
      "     [-0.3019608   0.04313726  0.34117648]\n",
      "     [-0.30980393  0.03529412  0.33333334]\n",
      "     [-0.31764707  0.02745098  0.3254902 ]]\n",
      "\n",
      "    [[-0.21568628  0.12941177  0.41960785]\n",
      "     [-0.21568628  0.12941177  0.41960785]\n",
      "     [-0.21568628  0.12941177  0.41960785]\n",
      "     ...\n",
      "     [-0.28627452  0.05098039  0.34901962]\n",
      "     [-0.3019608   0.05098039  0.34117648]\n",
      "     [-0.3019608   0.04313726  0.33333334]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.70980394 -0.6862745  -0.70980394]\n",
      "     [-0.69411767 -0.67058825 -0.69411767]\n",
      "     [-0.6784314  -0.654902   -0.6862745 ]\n",
      "     ...\n",
      "     [-0.25490198 -0.1764706  -0.60784316]\n",
      "     [-0.2627451  -0.2        -0.6156863 ]\n",
      "     [-0.27058825 -0.20784314 -0.62352943]]\n",
      "\n",
      "    [[-0.67058825 -0.6627451  -0.6784314 ]\n",
      "     [-0.654902   -0.6392157  -0.6627451 ]\n",
      "     [-0.654902   -0.6392157  -0.6627451 ]\n",
      "     ...\n",
      "     [-0.24705882 -0.18431373 -0.60784316]\n",
      "     [-0.28627452 -0.21568628 -0.6313726 ]\n",
      "     [-0.29411766 -0.22352941 -0.6392157 ]]\n",
      "\n",
      "    [[-0.6784314  -0.6627451  -0.6862745 ]\n",
      "     [-0.67058825 -0.654902   -0.6784314 ]\n",
      "     [-0.6627451  -0.64705884 -0.67058825]\n",
      "     ...\n",
      "     [-0.1764706  -0.18431373 -0.58431375]\n",
      "     [-0.25490198 -0.24705882 -0.6392157 ]\n",
      "     [-0.2784314  -0.2627451  -0.6627451 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[-0.75686276 -0.6862745  -0.67058825]\n",
      "     [-0.15294118  0.00392157  0.08235294]\n",
      "     [-0.48235294 -0.34117648 -0.25490198]\n",
      "     ...\n",
      "     [ 0.14509805  0.3254902   0.44313726]\n",
      "     [ 0.09803922  0.2784314   0.40392157]\n",
      "     [ 0.13725491  0.28627452  0.38039216]]\n",
      "\n",
      "    [[-0.73333335 -0.64705884 -0.5764706 ]\n",
      "     [-0.67058825 -0.5764706  -0.5686275 ]\n",
      "     [-0.6313726  -0.52156866 -0.5372549 ]\n",
      "     ...\n",
      "     [-0.28627452 -0.11372549 -0.04313726]\n",
      "     [-0.33333334 -0.11372549 -0.04313726]\n",
      "     [-0.23137255 -0.05098039  0.02745098]]\n",
      "\n",
      "    [[-0.24705882 -0.13725491 -0.02745098]\n",
      "     [-0.78039217 -0.69411767 -0.6392157 ]\n",
      "     [-0.5764706  -0.45882353 -0.43529412]\n",
      "     ...\n",
      "     [-0.52156866 -0.39607844 -0.30980393]\n",
      "     [-0.5137255  -0.37254903 -0.3019608 ]\n",
      "     [-0.5058824  -0.3882353  -0.3019608 ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.8745098  -0.7490196  -0.8039216 ]\n",
      "     [-0.8117647  -0.70980394 -0.73333335]\n",
      "     [-0.7882353  -0.6784314  -0.7019608 ]\n",
      "     ...\n",
      "     [-0.90588236 -0.62352943 -0.9137255 ]\n",
      "     [-0.8980392  -0.6156863  -0.8901961 ]\n",
      "     [-0.8901961  -0.6392157  -0.8980392 ]]\n",
      "\n",
      "    [[-0.8980392  -0.7647059  -0.827451  ]\n",
      "     [-0.8039216  -0.69411767 -0.73333335]\n",
      "     [-0.7490196  -0.6392157  -0.67058825]\n",
      "     ...\n",
      "     [-0.88235295 -0.58431375 -0.8980392 ]\n",
      "     [-0.8980392  -0.58431375 -0.8980392 ]\n",
      "     [-0.8901961  -0.60784316 -0.8980392 ]]\n",
      "\n",
      "    [[-0.8980392  -0.7882353  -0.827451  ]\n",
      "     [-0.79607844 -0.70980394 -0.70980394]\n",
      "     [-0.85882354 -0.75686276 -0.7647059 ]\n",
      "     ...\n",
      "     [-0.8745098  -0.5764706  -0.90588236]\n",
      "     [-0.90588236 -0.58431375 -0.92156863]\n",
      "     [-0.8901961  -0.5921569  -0.92156863]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[-0.7882353  -0.42745098  0.09803922]\n",
      "     [-0.77254903 -0.41960785  0.10588235]\n",
      "     [-0.77254903 -0.40392157  0.12156863]\n",
      "     ...\n",
      "     [-0.7254902  -0.33333334  0.18431373]\n",
      "     [-0.7254902  -0.34117648  0.1764706 ]\n",
      "     [-0.73333335 -0.34901962  0.16862746]]\n",
      "\n",
      "    [[-0.77254903 -0.4117647   0.12156863]\n",
      "     [-0.75686276 -0.40392157  0.12941177]\n",
      "     [-0.77254903 -0.3882353   0.13725491]\n",
      "     ...\n",
      "     [-0.7254902  -0.31764707  0.20784314]\n",
      "     [-0.7254902  -0.31764707  0.19215687]\n",
      "     [-0.7254902  -0.3254902   0.1764706 ]]\n",
      "\n",
      "    [[-0.77254903 -0.3882353   0.13725491]\n",
      "     [-0.75686276 -0.3882353   0.15294118]\n",
      "     [-0.7490196  -0.3647059   0.16862746]\n",
      "     ...\n",
      "     [-0.7019608  -0.29411766  0.21568628]\n",
      "     [-0.70980394 -0.3019608   0.21568628]\n",
      "     [-0.70980394 -0.30980393  0.19215687]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.6784314  -0.5529412  -0.90588236]\n",
      "     [-0.67058825 -0.56078434 -0.90588236]\n",
      "     [-0.654902   -0.56078434 -0.8901961 ]\n",
      "     ...\n",
      "     [-0.9764706  -0.92941177 -0.9843137 ]\n",
      "     [-0.9764706  -0.9372549  -0.9843137 ]\n",
      "     [-0.9843137  -0.9372549  -0.9843137 ]]\n",
      "\n",
      "    [[-0.6392157  -0.5529412  -0.8745098 ]\n",
      "     [-0.6313726  -0.5529412  -0.8901961 ]\n",
      "     [-0.6156863  -0.5529412  -0.88235295]\n",
      "     ...\n",
      "     [-0.9764706  -0.9372549  -0.99215686]\n",
      "     [-0.9764706  -0.9372549  -0.99215686]\n",
      "     [-0.9843137  -0.92941177 -0.99215686]]\n",
      "\n",
      "    [[-0.6862745  -0.6        -0.90588236]\n",
      "     [-0.6392157  -0.58431375 -0.8980392 ]\n",
      "     [-0.62352943 -0.5764706  -0.8901961 ]\n",
      "     ...\n",
      "     [-0.9843137  -0.92156863 -0.99215686]\n",
      "     [-0.9843137  -0.9372549  -0.99215686]\n",
      "     [-0.9843137  -0.92941177 -0.9843137 ]]]]]]\n",
      "[1 1 1 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle Dataset\n",
    "data, labels = unison_shuffled_copies(data, labels)\n",
    "\n",
    "show_amount = 10\n",
    "print(data[:show_amount])\n",
    "print(labels[:show_amount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SPLIT: 0 - 888 | 888 | 80.0%\n",
      "VALIDATION SPLIT: 888 - 999 | 111 | 10.0%\n",
      "TEST SPLIT: 999 - 1110 | 111 | 10.0%\n",
      "---\n",
      "Training Data Shape: (888, 2, 1, 224, 224, 3)\n",
      "Validation Data Shape: (111, 2, 1, 224, 224, 3)\n",
      "Test Data Shape: (111, 2, 1, 224, 224, 3)\n",
      "---\n",
      "Training Labels Shape: (888,)\n",
      "Validation Labels Shape: (111,)\n",
      "Test Labels Shape: (111,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train, validation, and test\n",
    "\n",
    "train_split = int(DATA_TRAIN_SPLIT * len(data))\n",
    "validation_split = train_split+int(DATA_VALIDATION_SPLIT * len(data))\n",
    "\n",
    "print(\"TRAIN SPLIT: \" + \"0 - \" + str(train_split) + \" | \" + str(train_split) + \" | \" + str(DATA_TRAIN_SPLIT*100) + '%')\n",
    "print(\"VALIDATION SPLIT: \" + str(train_split) + \" - \" + str(validation_split) + \" | \" + str(validation_split-train_split) + \" | \" + str(DATA_VALIDATION_SPLIT*100) + '%')\n",
    "print(\"TEST SPLIT: \" + str(validation_split) + \" - \" + str(len(data)) + \" | \" + str(len(data) - validation_split) + \" | \" + str(100 - DATA_TRAIN_SPLIT*100 - DATA_VALIDATION_SPLIT*100) + '%')\n",
    "\n",
    "data_train = data[0:train_split]\n",
    "data_validation = data[train_split:validation_split]\n",
    "data_test = data[validation_split:]\n",
    "\n",
    "labels_train = labels[0:train_split]\n",
    "labels_validation = labels[train_split:validation_split]\n",
    "labels_test = labels[validation_split:]\n",
    "\n",
    "print(\"---\")\n",
    "print(\"Training Data Shape: \" + str(data_train.shape))\n",
    "print(\"Validation Data Shape: \" + str(data_validation.shape))\n",
    "print(\"Test Data Shape: \" + str(data_test.shape))\n",
    "print(\"---\")\n",
    "print(\"Training Labels Shape: \" + str(labels_train.shape))\n",
    "print(\"Validation Labels Shape: \" + str(labels_validation.shape))\n",
    "print(\"Test Labels Shape: \" + str(labels_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractor M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 1280)         2257984     ['input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# embedding extractor\n",
    "embedding_extractor = Sequential()\n",
    "base_model = MobileNetV2(input_shape=input_shape, include_top = False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "embedding_extractor.add(base_model)\n",
    "\n",
    "embedding_extractor.add(GlobalAveragePooling2D())\n",
    "\n",
    "embedding_extractor.summary()\n",
    "\n",
    "# Input pair\n",
    "input_image_1 = Input(input_shape)\n",
    "input_image_2 = Input(input_shape)\n",
    "\n",
    "# Output pair\n",
    "encoded_image_1 = embedding_extractor(input_image_1)\n",
    "encoded_image_2 = embedding_extractor(input_image_2)\n",
    "\n",
    "# Model\n",
    "feature_extractor = Model(inputs=[input_image_1, input_image_2], outputs=[encoded_image_1, encoded_image_2])\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Exception encountered when calling layer \"model_1\" (type Functional).\n\nCould not compute output KerasTensor(type_spec=TensorSpec(shape=(None, 1280), dtype=tf.float32, name=None), name='sequential_2/global_average_pooling2d_1/Mean:0', description=\"created by layer 'sequential_2'\")\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 224, 224, 3), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20136/1192763197.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mm3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# m3.summary()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[0mx_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m       \u001b[1;32massert\u001b[0m \u001b[0mx_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Could not compute output '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m       \u001b[0moutput_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Exception encountered when calling layer \"model_1\" (type Functional).\n\nCould not compute output KerasTensor(type_spec=TensorSpec(shape=(None, 1280), dtype=tf.float32, name=None), name='sequential_2/global_average_pooling2d_1/Mean:0', description=\"created by layer 'sequential_2'\")\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 224, 224, 3), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "\n",
    "def euclidean_distance(vects):\n",
    "    x = vects[0]\n",
    "    y = vects[1]\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "m3 = Sequential()\n",
    "\n",
    "ex = feature_extractor\n",
    "\n",
    "m3.add(ex)\n",
    "# m3.summary()\n",
    "\n",
    "# m3.add(Lambda(euclidean_distance))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95bedf10bfb8ab76b52888e4286a107c64e826336c41c64851a50835c33f2a43"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
