{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\anton\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\anton\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\anton\\anaconda3\\lib\\site-packages (1.21.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\anton\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\anton\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anton\\anaconda3\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Resizing\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.metrics import CosineSimilarity\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pixels(image):\n",
    "    \"\"\"normalize pixels to be between 0 and 1\"\"\"\n",
    "\n",
    "\t# convert from integers to floats\n",
    "    image_norm = image.astype('float32')\n",
    "\t# normalize to range -1 and 1\n",
    "    image_norm = (image_norm - 127.5) / 127.5\n",
    "\n",
    "\t# return normalized images\n",
    "    return image_norm\n",
    "\n",
    "def de_normalize_pixels(image, _from = 0, _to = 1):\n",
    "    \"\"\"de-normalize pixels to be between 0 and 255\"\"\"\n",
    "\n",
    "    # Normalize between 0 and 1\n",
    "    image_de_norm = (image * 127.5) + 127.5\n",
    "\n",
    "    # Normalize between 0 and 1\n",
    "    image_de_norm = image_de_norm/255 \n",
    "\n",
    "    # Normalize between _from and _to\n",
    "    image_de_norm = (image_de_norm * (_to - _from)) + _from\n",
    "    \n",
    "    return image_de_norm\n",
    "\n",
    "def load_image(path):\n",
    "    \"\"\"load image from path and convert to array\"\"\"\n",
    "\n",
    "    img = load_img(path, target_size=(224, 224), interpolation='bilinear')\n",
    "    x = img_to_array(img)\n",
    "    x = normalize_pixels(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return x\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    \"\"\"shuffle two arrays in unison\"\"\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "def pairwise_euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.square(x - y)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/dataset'\n",
    "DATA_TRAIN_SPLIT = 0.8\n",
    "DATA_VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of images: 555\n"
     ]
    }
   ],
   "source": [
    "# Load images into arrays\n",
    "import pathlib\n",
    "\n",
    "data_dir = pathlib.Path(DATA_PATH)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')) + list(data_dir.glob('*/*.jpeg')) + list(data_dir.glob('*/*.png')))\n",
    "print(\"Total amount of images: \" + str(image_count))\n",
    "\n",
    "folders = [x for x in data_dir.iterdir() if x.is_dir()]\n",
    "\n",
    "img_array_data = []\n",
    "\n",
    "for i, folder in enumerate(folders):\n",
    "    img_array_data.append([])\n",
    "\n",
    "    for j, img in enumerate(folder.iterdir()):\n",
    "        img_array_data[i].append(load_image(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Create image pairs\n",
    "def create_image_pairs(images):\n",
    "    for i, array in enumerate(images):\n",
    "        for j in range(len(array)):\n",
    "            # True\n",
    "            data.append([\n",
    "                images[i][j], \n",
    "                images[i][np.random.randint(0, len(images[i]) - 1)]])\n",
    "            labels.append(1)\n",
    "\n",
    "            x_1 = np.random.randint(0, len(images) - 1)\n",
    "            x_2 = np.random.randint(0, len(images[x_1]) - 1)\n",
    "\n",
    "            # False\n",
    "            data.append([\n",
    "                images[i][j], \n",
    "                images[x_1][x_2]])\n",
    "            labels.append(0)\n",
    "\n",
    "create_image_pairs(img_array_data)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[[-0.70980394 -0.41960785 -0.01176471]\n",
      "     [-0.7254902  -0.4117647  -0.01176471]\n",
      "     [-0.7254902  -0.4117647  -0.01176471]\n",
      "     ...\n",
      "     [-0.7176471  -0.5137255  -0.09019608]\n",
      "     [-0.7647059  -0.7411765  -0.6392157 ]\n",
      "     [-0.81960785 -0.8117647  -0.84313726]]\n",
      "\n",
      "    [[-0.7254902  -0.4117647  -0.01176471]\n",
      "     [-0.7254902  -0.40392157 -0.01176471]\n",
      "     [-0.7254902  -0.40392157 -0.00392157]\n",
      "     ...\n",
      "     [-0.7254902  -0.46666667 -0.03529412]\n",
      "     [-0.7254902  -0.6862745  -0.52156866]\n",
      "     [-0.8117647  -0.78039217 -0.7882353 ]]\n",
      "\n",
      "    [[-0.7254902  -0.4117647  -0.00392157]\n",
      "     [-0.7254902  -0.4117647  -0.00392157]\n",
      "     [-0.7254902  -0.4117647  -0.00392157]\n",
      "     ...\n",
      "     [-0.7254902  -0.43529412  0.01960784]\n",
      "     [-0.7176471  -0.6392157  -0.39607844]\n",
      "     [-0.8039216  -0.7647059  -0.75686276]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.6392157  -0.6627451  -0.6784314 ]\n",
      "     [-0.7254902  -0.75686276 -0.8039216 ]\n",
      "     [-0.6        -0.654902   -0.7019608 ]\n",
      "     ...\n",
      "     [-0.24705882 -0.29411766 -0.34117648]\n",
      "     [ 0.09803922 -0.00392157 -0.12941177]\n",
      "     [ 0.09803922  0.03529412 -0.10588235]]\n",
      "\n",
      "    [[-0.6862745  -0.7019608  -0.73333335]\n",
      "     [-0.8117647  -0.8352941  -0.8745098 ]\n",
      "     [-0.64705884 -0.69411767 -0.7411765 ]\n",
      "     ...\n",
      "     [-0.58431375 -0.5921569  -0.64705884]\n",
      "     [-0.01960784 -0.06666667 -0.1764706 ]\n",
      "     [ 0.08235294  0.08235294 -0.02745098]]\n",
      "\n",
      "    [[-0.7019608  -0.70980394 -0.7490196 ]\n",
      "     [-0.8117647  -0.81960785 -0.88235295]\n",
      "     [-0.6627451  -0.7019608  -0.7490196 ]\n",
      "     ...\n",
      "     [-0.62352943 -0.60784316 -0.6627451 ]\n",
      "     [-0.2        -0.19215687 -0.16862746]\n",
      "     [-0.18431373 -0.18431373 -0.13725491]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 0.8352941   0.88235295  0.9764706 ]\n",
      "     [ 0.81960785  0.88235295  0.9764706 ]\n",
      "     [ 0.81960785  0.8745098   0.9764706 ]\n",
      "     ...\n",
      "     [ 0.84313726  0.8980392   0.9764706 ]\n",
      "     [ 0.84313726  0.8980392   0.9764706 ]\n",
      "     [ 0.8352941   0.8901961   0.96862745]]\n",
      "\n",
      "    [[ 0.8352941   0.88235295  0.9764706 ]\n",
      "     [ 0.8352941   0.88235295  0.9764706 ]\n",
      "     [ 0.8352941   0.8901961   0.9764706 ]\n",
      "     ...\n",
      "     [ 0.8666667   0.90588236  0.9764706 ]\n",
      "     [ 0.85882354  0.90588236  0.9843137 ]\n",
      "     [ 0.8509804   0.8980392   0.9764706 ]]\n",
      "\n",
      "    [[ 0.8352941   0.88235295  0.9764706 ]\n",
      "     [ 0.8352941   0.8901961   0.9764706 ]\n",
      "     [ 0.84313726  0.90588236  0.9843137 ]\n",
      "     ...\n",
      "     [ 0.9137255   0.92941177  0.9764706 ]\n",
      "     [ 0.90588236  0.92941177  0.9843137 ]\n",
      "     [ 0.8980392   0.92156863  0.9764706 ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.56078434 -0.41960785 -0.73333335]\n",
      "     [-0.58431375 -0.44313726 -0.7647059 ]\n",
      "     [-0.5921569  -0.43529412 -0.77254903]\n",
      "     ...\n",
      "     [-0.5921569  -0.41960785 -0.70980394]\n",
      "     [-0.58431375 -0.4509804  -0.70980394]\n",
      "     [-0.60784316 -0.4745098  -0.7411765 ]]\n",
      "\n",
      "    [[-0.5686275  -0.44313726 -0.7490196 ]\n",
      "     [-0.5764706  -0.43529412 -0.7490196 ]\n",
      "     [-0.5764706  -0.41960785 -0.75686276]\n",
      "     ...\n",
      "     [-0.6313726  -0.42745098 -0.7647059 ]\n",
      "     [-0.5921569  -0.41960785 -0.7411765 ]\n",
      "     [-0.60784316 -0.44313726 -0.75686276]]\n",
      "\n",
      "    [[-0.5529412  -0.42745098 -0.73333335]\n",
      "     [-0.56078434 -0.41960785 -0.7254902 ]\n",
      "     [-0.54509807 -0.40392157 -0.7254902 ]\n",
      "     ...\n",
      "     [-0.5921569  -0.40392157 -0.75686276]\n",
      "     [-0.62352943 -0.4117647  -0.77254903]\n",
      "     [-0.6313726  -0.42745098 -0.78039217]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[-0.56078434 -0.25490198  0.14509805]\n",
      "     [-0.5529412  -0.24705882  0.16078432]\n",
      "     [-0.54509807 -0.23921569  0.16862746]\n",
      "     ...\n",
      "     [-0.45882353 -0.19215687  0.23137255]\n",
      "     [-0.45882353 -0.18431373  0.23137255]\n",
      "     [-0.45882353 -0.19215687  0.22352941]]\n",
      "\n",
      "    [[-0.54509807 -0.24705882  0.15294118]\n",
      "     [-0.54509807 -0.24705882  0.16862746]\n",
      "     [-0.54509807 -0.23137255  0.16078432]\n",
      "     ...\n",
      "     [-0.4509804  -0.1764706   0.23921569]\n",
      "     [-0.46666667 -0.1764706   0.23921569]\n",
      "     [-0.4509804  -0.18431373  0.22352941]]\n",
      "\n",
      "    [[-0.54509807 -0.23921569  0.16862746]\n",
      "     [-0.5372549  -0.24705882  0.1764706 ]\n",
      "     [-0.5372549  -0.23921569  0.1764706 ]\n",
      "     ...\n",
      "     [-0.44313726 -0.1764706   0.24705882]\n",
      "     [-0.44313726 -0.16862746  0.25490198]\n",
      "     [-0.4509804  -0.1764706   0.2627451 ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.99215686 -0.9764706  -1.        ]\n",
      "     [-1.         -0.9843137  -0.99215686]\n",
      "     [-1.         -0.9843137  -0.99215686]\n",
      "     ...\n",
      "     [ 0.12156863  0.04313726 -0.12941177]\n",
      "     [ 0.2784314   0.18431373 -0.04313726]\n",
      "     [ 0.24705882  0.09019608 -0.18431373]]\n",
      "\n",
      "    [[-0.99215686 -0.9843137  -1.        ]\n",
      "     [-0.99215686 -0.9843137  -0.99215686]\n",
      "     [-0.99215686 -0.9764706  -0.99215686]\n",
      "     ...\n",
      "     [ 0.07450981  0.00392157 -0.12156863]\n",
      "     [ 0.09803922 -0.00392157 -0.1764706 ]\n",
      "     [ 0.05882353 -0.05098039 -0.2       ]]\n",
      "\n",
      "    [[-0.99215686 -0.9764706  -1.        ]\n",
      "     [-0.99215686 -0.9843137  -0.99215686]\n",
      "     [-0.99215686 -0.9764706  -0.99215686]\n",
      "     ...\n",
      "     [-0.29411766 -0.39607844 -0.48235294]\n",
      "     [-0.05882353 -0.14509805 -0.27058825]\n",
      "     [-0.00392157 -0.10588235 -0.21568628]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[-0.03529412  0.02745098  0.1764706 ]\n",
      "     [-0.04313726  0.01960784  0.16862746]\n",
      "     [-0.05098039  0.02745098  0.16862746]\n",
      "     ...\n",
      "     [ 0.2         0.2627451   0.3647059 ]\n",
      "     [ 0.2         0.2627451   0.3647059 ]\n",
      "     [ 0.2         0.2627451   0.3647059 ]]\n",
      "\n",
      "    [[-0.04313726  0.01960784  0.16862746]\n",
      "     [-0.04313726  0.01960784  0.16862746]\n",
      "     [-0.04313726  0.02745098  0.1764706 ]\n",
      "     ...\n",
      "     [ 0.2         0.2627451   0.3647059 ]\n",
      "     [ 0.2         0.2627451   0.3647059 ]\n",
      "     [ 0.2         0.2627451   0.3647059 ]]\n",
      "\n",
      "    [[-0.04313726  0.01960784  0.16862746]\n",
      "     [-0.04313726  0.01960784  0.16862746]\n",
      "     [-0.05098039  0.02745098  0.1764706 ]\n",
      "     ...\n",
      "     [ 0.2         0.2627451   0.3647059 ]\n",
      "     [ 0.19215687  0.25490198  0.35686275]\n",
      "     [ 0.2         0.2627451   0.3647059 ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.79607844 -0.79607844 -0.8352941 ]\n",
      "     [-0.7490196  -0.7490196  -0.79607844]\n",
      "     [-0.7254902  -0.7176471  -0.77254903]\n",
      "     ...\n",
      "     [-0.81960785 -0.8117647  -0.8509804 ]\n",
      "     [-0.8352941  -0.84313726 -0.8745098 ]\n",
      "     [-0.79607844 -0.81960785 -0.8509804 ]]\n",
      "\n",
      "    [[-0.8039216  -0.79607844 -0.84313726]\n",
      "     [-0.7411765  -0.7411765  -0.7882353 ]\n",
      "     [-0.7254902  -0.7254902  -0.7647059 ]\n",
      "     ...\n",
      "     [-0.8352941  -0.827451   -0.8666667 ]\n",
      "     [-0.8352941  -0.8352941  -0.8745098 ]\n",
      "     [-0.79607844 -0.81960785 -0.8509804 ]]\n",
      "\n",
      "    [[-0.79607844 -0.81960785 -0.8509804 ]\n",
      "     [-0.73333335 -0.7490196  -0.78039217]\n",
      "     [-0.7411765  -0.7490196  -0.7882353 ]\n",
      "     ...\n",
      "     [-0.84313726 -0.8352941  -0.8745098 ]\n",
      "     [-0.8509804  -0.84313726 -0.88235295]\n",
      "     [-0.8352941  -0.827451   -0.8666667 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[ 0.39607844  0.5372549   0.8039216 ]\n",
      "     [ 0.41960785  0.56078434  0.827451  ]\n",
      "     [ 0.44313726  0.5921569   0.8352941 ]\n",
      "     ...\n",
      "     [ 0.35686275  0.42745098  0.75686276]\n",
      "     [ 0.34117648  0.42745098  0.7490196 ]\n",
      "     [ 0.3254902   0.42745098  0.7411765 ]]\n",
      "\n",
      "    [[ 0.37254903  0.5294118   0.8039216 ]\n",
      "     [ 0.39607844  0.54509807  0.8117647 ]\n",
      "     [ 0.40392157  0.56078434  0.8117647 ]\n",
      "     ...\n",
      "     [ 0.3647059   0.44313726  0.7647059 ]\n",
      "     [ 0.34117648  0.43529412  0.75686276]\n",
      "     [ 0.33333334  0.42745098  0.7490196 ]]\n",
      "\n",
      "    [[ 0.34117648  0.4745098   0.79607844]\n",
      "     [ 0.34901962  0.49803922  0.8039216 ]\n",
      "     [ 0.37254903  0.5137255   0.7882353 ]\n",
      "     ...\n",
      "     [ 0.3647059   0.44313726  0.77254903]\n",
      "     [ 0.34901962  0.44313726  0.75686276]\n",
      "     [ 0.33333334  0.43529412  0.7490196 ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.8666667  -0.8039216  -0.8745098 ]\n",
      "     [-0.8666667  -0.8039216  -0.88235295]\n",
      "     [-0.85882354 -0.8039216  -0.8901961 ]\n",
      "     ...\n",
      "     [-0.48235294 -0.44313726 -0.4117647 ]\n",
      "     [-0.49803922 -0.4745098  -0.42745098]\n",
      "     [-0.5058824  -0.5058824  -0.4509804 ]]\n",
      "\n",
      "    [[-0.8666667  -0.8117647  -0.8745098 ]\n",
      "     [-0.8666667  -0.8039216  -0.88235295]\n",
      "     [-0.8666667  -0.8117647  -0.88235295]\n",
      "     ...\n",
      "     [-0.46666667 -0.4509804  -0.41960785]\n",
      "     [-0.4745098  -0.45882353 -0.42745098]\n",
      "     [-0.49803922 -0.48235294 -0.4509804 ]]\n",
      "\n",
      "    [[-0.8745098  -0.81960785 -0.88235295]\n",
      "     [-0.8745098  -0.8117647  -0.88235295]\n",
      "     [-0.8666667  -0.8117647  -0.88235295]\n",
      "     ...\n",
      "     [-0.46666667 -0.46666667 -0.42745098]\n",
      "     [-0.46666667 -0.45882353 -0.43529412]\n",
      "     [-0.4745098  -0.45882353 -0.44313726]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[-0.39607844 -0.4117647  -0.5137255 ]\n",
      "     [-0.43529412 -0.44313726 -0.54509807]\n",
      "     [-0.44313726 -0.44313726 -0.5372549 ]\n",
      "     ...\n",
      "     [ 0.6784314   0.7019608   0.7882353 ]\n",
      "     [ 0.6784314   0.70980394  0.7882353 ]\n",
      "     [ 0.67058825  0.7019608   0.78039217]]\n",
      "\n",
      "    [[-0.35686275 -0.34901962 -0.45882353]\n",
      "     [-0.39607844 -0.39607844 -0.49803922]\n",
      "     [-0.39607844 -0.4117647  -0.5137255 ]\n",
      "     ...\n",
      "     [ 0.7254902   0.75686276  0.8039216 ]\n",
      "     [ 0.69411767  0.73333335  0.8039216 ]\n",
      "     [ 0.6627451   0.69411767  0.7882353 ]]\n",
      "\n",
      "    [[-0.3647059  -0.35686275 -0.46666667]\n",
      "     [-0.38039216 -0.37254903 -0.4745098 ]\n",
      "     [-0.3882353  -0.39607844 -0.49019608]\n",
      "     ...\n",
      "     [ 0.70980394  0.7411765   0.8117647 ]\n",
      "     [ 0.6784314   0.70980394  0.79607844]\n",
      "     [ 0.6313726   0.67058825  0.7647059 ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.99215686 -0.99215686 -0.99215686]\n",
      "     [-0.99215686 -0.99215686 -0.99215686]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     ...\n",
      "     [-0.37254903 -0.16862746 -0.73333335]\n",
      "     [-0.34901962 -0.14509805 -0.7254902 ]\n",
      "     [-0.35686275 -0.15294118 -0.7411765 ]]\n",
      "\n",
      "    [[-0.99215686 -0.99215686 -0.99215686]\n",
      "     [-0.99215686 -0.99215686 -0.99215686]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     ...\n",
      "     [-0.38039216 -0.16862746 -0.75686276]\n",
      "     [-0.37254903 -0.16862746 -0.7490196 ]\n",
      "     [-0.3882353  -0.15294118 -0.7490196 ]]\n",
      "\n",
      "    [[-0.99215686 -0.99215686 -0.99215686]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     ...\n",
      "     [-0.3882353  -0.16862746 -0.7647059 ]\n",
      "     [-0.3882353  -0.16078432 -0.7490196 ]\n",
      "     [-0.38039216 -0.16078432 -0.75686276]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[ 0.7019608   0.70980394  0.77254903]\n",
      "     [ 0.7019608   0.7176471   0.77254903]\n",
      "     [ 0.7176471   0.7176471   0.77254903]\n",
      "     ...\n",
      "     [-0.81960785 -0.8352941  -0.8666667 ]\n",
      "     [-0.85882354 -0.8745098  -0.8901961 ]\n",
      "     [-0.8666667  -0.8745098  -0.8901961 ]]\n",
      "\n",
      "    [[ 0.69411767  0.7176471   0.7411765 ]\n",
      "     [ 0.7176471   0.7254902   0.7647059 ]\n",
      "     [ 0.7254902   0.7254902   0.78039217]\n",
      "     ...\n",
      "     [-0.77254903 -0.81960785 -0.8352941 ]\n",
      "     [-0.84313726 -0.8509804  -0.88235295]\n",
      "     [-0.8745098  -0.8745098  -0.8980392 ]]\n",
      "\n",
      "    [[ 0.69411767  0.7176471   0.7490196 ]\n",
      "     [ 0.7176471   0.7254902   0.7647059 ]\n",
      "     [ 0.7254902   0.7254902   0.77254903]\n",
      "     ...\n",
      "     [-0.7411765  -0.7882353  -0.8117647 ]\n",
      "     [-0.84313726 -0.8509804  -0.88235295]\n",
      "     [-0.8745098  -0.8666667  -0.8980392 ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.44313726 -0.5137255  -0.6       ]\n",
      "     [-0.5137255  -0.54509807 -0.60784316]\n",
      "     [-0.5294118  -0.56078434 -0.5921569 ]\n",
      "     ...\n",
      "     [-0.9607843  -0.9529412  -0.9607843 ]\n",
      "     [-0.9607843  -0.9529412  -0.9607843 ]\n",
      "     [-0.9607843  -0.9529412  -0.9529412 ]]\n",
      "\n",
      "    [[-0.5372549  -0.5372549  -0.62352943]\n",
      "     [-0.56078434 -0.6        -0.6627451 ]\n",
      "     [-0.5921569  -0.6156863  -0.654902  ]\n",
      "     ...\n",
      "     [-0.96862745 -0.96862745 -0.96862745]\n",
      "     [-0.9607843  -0.9607843  -0.9607843 ]\n",
      "     [-0.9607843  -0.9607843  -0.9607843 ]]\n",
      "\n",
      "    [[-0.5764706  -0.5686275  -0.654902  ]\n",
      "     [-0.6156863  -0.6156863  -0.67058825]\n",
      "     [-0.6392157  -0.654902   -0.6862745 ]\n",
      "     ...\n",
      "     [-0.96862745 -0.96862745 -0.96862745]\n",
      "     [-0.96862745 -0.96862745 -0.96862745]\n",
      "     [-0.96862745 -0.96862745 -0.96862745]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     ...\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]]\n",
      "\n",
      "    [[-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     ...\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]]\n",
      "\n",
      "    [[-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     ...\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.99215686 -0.9764706  -1.        ]\n",
      "     [-0.99215686 -0.9843137  -1.        ]\n",
      "     [-0.9843137  -0.9764706  -1.        ]\n",
      "     ...\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]]\n",
      "\n",
      "    [[-0.99215686 -0.9843137  -1.        ]\n",
      "     [-0.99215686 -0.99215686 -1.        ]\n",
      "     [-0.99215686 -0.9843137  -1.        ]\n",
      "     ...\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]]\n",
      "\n",
      "    [[-0.99215686 -0.9843137  -1.        ]\n",
      "     [-0.99215686 -0.9843137  -1.        ]\n",
      "     [-0.99215686 -0.9843137  -1.        ]\n",
      "     ...\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]\n",
      "     [-1.         -1.         -1.        ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[ 0.18431373  0.18431373  0.18431373]\n",
      "     [-0.2784314  -0.2784314  -0.2784314 ]\n",
      "     [-0.28627452 -0.28627452 -0.28627452]\n",
      "     ...\n",
      "     [-0.28627452 -0.28627452 -0.28627452]\n",
      "     [-0.23137255 -0.23137255 -0.23137255]\n",
      "     [ 0.56078434  0.56078434  0.56078434]]\n",
      "\n",
      "    [[-0.5058824  -0.5058824  -0.5058824 ]\n",
      "     [-0.9529412  -0.9529412  -0.9529412 ]\n",
      "     [-0.9529412  -0.9529412  -0.9529412 ]\n",
      "     ...\n",
      "     [-0.9607843  -0.9607843  -0.9607843 ]\n",
      "     [-0.9372549  -0.9372549  -0.9372549 ]\n",
      "     [ 0.09019608  0.09019608  0.09019608]]\n",
      "\n",
      "    [[-0.52156866 -0.52156866 -0.52156866]\n",
      "     [-0.78039217 -0.78039217 -0.78039217]\n",
      "     [-0.3019608  -0.3019608  -0.3019608 ]\n",
      "     ...\n",
      "     [-0.24705882 -0.24705882 -0.24705882]\n",
      "     [-0.8666667  -0.8666667  -0.8666667 ]\n",
      "     [ 0.07450981  0.07450981  0.07450981]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.07450981 -0.07450981 -0.07450981]\n",
      "     [-0.5686275  -0.5686275  -0.5686275 ]\n",
      "     [-0.5764706  -0.5764706  -0.5764706 ]\n",
      "     ...\n",
      "     [-0.5764706  -0.5764706  -0.5764706 ]\n",
      "     [-0.5372549  -0.5372549  -0.5372549 ]\n",
      "     [ 0.37254903  0.37254903  0.37254903]]\n",
      "\n",
      "    [[ 0.9137255   0.9137255   0.9137255 ]\n",
      "     [ 0.8352941   0.8352941   0.8352941 ]\n",
      "     [ 0.8352941   0.8352941   0.8352941 ]\n",
      "     ...\n",
      "     [ 0.8352941   0.8352941   0.8352941 ]\n",
      "     [ 0.84313726  0.84313726  0.84313726]\n",
      "     [ 0.9529412   0.9529412   0.9529412 ]]\n",
      "\n",
      "    [[ 0.99215686  0.99215686  0.99215686]\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]\n",
      "     ...\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]\n",
      "     [ 1.          1.          1.        ]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 0.09019608  0.08235294  0.12156863]\n",
      "     [ 0.09803922  0.09019608  0.12941177]\n",
      "     [ 0.09019608  0.09019608  0.13725491]\n",
      "     ...\n",
      "     [-0.23921569 -0.20784314 -0.12941177]\n",
      "     [-0.23921569 -0.20784314 -0.12941177]\n",
      "     [-0.23921569 -0.20784314 -0.13725491]]\n",
      "\n",
      "    [[ 0.09019608  0.09803922  0.13725491]\n",
      "     [ 0.09803922  0.10588235  0.14509805]\n",
      "     [ 0.09019608  0.10588235  0.14509805]\n",
      "     ...\n",
      "     [-0.23921569 -0.19215687 -0.12156863]\n",
      "     [-0.22352941 -0.2        -0.12156863]\n",
      "     [-0.22352941 -0.2        -0.12941177]]\n",
      "\n",
      "    [[ 0.10588235  0.10588235  0.14509805]\n",
      "     [ 0.10588235  0.10588235  0.14509805]\n",
      "     [ 0.10588235  0.10588235  0.15294118]\n",
      "     ...\n",
      "     [-0.23137255 -0.2        -0.11372549]\n",
      "     [-0.22352941 -0.2        -0.11372549]\n",
      "     [-0.22352941 -0.2        -0.12156863]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.9372549  -0.92941177 -0.96862745]\n",
      "     [-0.92941177 -0.92156863 -0.9607843 ]\n",
      "     [-0.92941177 -0.92156863 -0.9607843 ]\n",
      "     ...\n",
      "     [-0.8666667  -0.84313726 -0.92941177]\n",
      "     [-0.8901961  -0.8745098  -0.94509804]\n",
      "     [-0.90588236 -0.8980392  -0.92941177]]\n",
      "\n",
      "    [[-0.94509804 -0.9372549  -0.9607843 ]\n",
      "     [-0.92941177 -0.92941177 -0.9607843 ]\n",
      "     [-0.94509804 -0.94509804 -0.96862745]\n",
      "     ...\n",
      "     [-0.8980392  -0.8901961  -0.92941177]\n",
      "     [-0.9137255  -0.90588236 -0.94509804]\n",
      "     [-0.92156863 -0.9137255  -0.9372549 ]]\n",
      "\n",
      "    [[-0.94509804 -0.94509804 -0.9607843 ]\n",
      "     [-0.94509804 -0.94509804 -0.9607843 ]\n",
      "     [-0.9529412  -0.9529412  -0.96862745]\n",
      "     ...\n",
      "     [-0.9137255  -0.8980392  -0.94509804]\n",
      "     [-0.9137255  -0.9137255  -0.94509804]\n",
      "     [-0.92156863 -0.92156863 -0.9372549 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[ 0.6862745   0.79607844  0.9843137 ]\n",
      "     [ 0.69411767  0.8039216   0.99215686]\n",
      "     [ 0.7019608   0.8117647   1.        ]\n",
      "     ...\n",
      "     [ 0.31764707  0.5372549   0.99215686]\n",
      "     [ 0.29411766  0.52156866  0.9843137 ]\n",
      "     [ 0.28627452  0.5058824   0.9764706 ]]\n",
      "\n",
      "    [[ 0.7176471   0.81960785  0.99215686]\n",
      "     [ 0.7176471   0.8352941   1.        ]\n",
      "     [ 0.73333335  0.8352941   1.        ]\n",
      "     ...\n",
      "     [ 0.31764707  0.56078434  0.99215686]\n",
      "     [ 0.30980393  0.54509807  0.99215686]\n",
      "     [ 0.3019608   0.5294118   1.        ]]\n",
      "\n",
      "    [[ 0.73333335  0.84313726  0.99215686]\n",
      "     [ 0.75686276  0.8509804   1.        ]\n",
      "     [ 0.78039217  0.8509804   0.99215686]\n",
      "     ...\n",
      "     [ 0.34117648  0.58431375  1.        ]\n",
      "     [ 0.34117648  0.56078434  0.99215686]\n",
      "     [ 0.3254902   0.5529412   1.        ]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[ 0.8352941   0.70980394  0.54509807]\n",
      "     [ 0.84313726  0.7176471   0.5529412 ]\n",
      "     [ 0.85882354  0.7490196   0.5921569 ]\n",
      "     ...\n",
      "     [ 0.23137255  0.16862746 -0.01960784]\n",
      "     [ 0.2         0.12941177 -0.03529412]\n",
      "     [ 0.23921569  0.16078432  0.00392157]]\n",
      "\n",
      "    [[ 0.7490196   0.60784316  0.5137255 ]\n",
      "     [ 0.8039216   0.654902    0.5372549 ]\n",
      "     [ 0.827451    0.7019608   0.5686275 ]\n",
      "     ...\n",
      "     [ 0.13725491  0.03529412 -0.05882353]\n",
      "     [ 0.15294118  0.05098039 -0.06666667]\n",
      "     [ 0.20784314  0.09803922 -0.00392157]]\n",
      "\n",
      "    [[ 0.09803922 -0.04313726  0.02745098]\n",
      "     [ 0.30980393  0.12156863  0.20784314]\n",
      "     [ 0.45882353  0.29411766  0.3254902 ]\n",
      "     ...\n",
      "     [ 0.13725491  0.05098039 -0.09803922]\n",
      "     [ 0.15294118  0.05882353 -0.09803922]\n",
      "     [ 0.15294118  0.04313726 -0.08235294]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 0.19215687  0.37254903  0.6392157 ]\n",
      "     [ 0.2         0.38039216  0.6313726 ]\n",
      "     [ 0.20784314  0.38039216  0.6392157 ]\n",
      "     ...\n",
      "     [ 0.37254903  0.43529412  0.52156866]\n",
      "     [ 0.3647059   0.42745098  0.52156866]\n",
      "     [ 0.35686275  0.41960785  0.52156866]]\n",
      "\n",
      "    [[ 0.19215687  0.38039216  0.6392157 ]\n",
      "     [ 0.2         0.3882353   0.6313726 ]\n",
      "     [ 0.20784314  0.3882353   0.6392157 ]\n",
      "     ...\n",
      "     [ 0.3647059   0.42745098  0.5294118 ]\n",
      "     [ 0.35686275  0.41960785  0.5294118 ]\n",
      "     [ 0.34901962  0.4117647   0.5294118 ]]\n",
      "\n",
      "    [[ 0.19215687  0.3882353   0.6313726 ]\n",
      "     [ 0.20784314  0.3882353   0.6392157 ]\n",
      "     [ 0.21568628  0.3882353   0.6392157 ]\n",
      "     ...\n",
      "     [ 0.34901962  0.4117647   0.52156866]\n",
      "     [ 0.34901962  0.40392157  0.52156866]\n",
      "     [ 0.34117648  0.40392157  0.52156866]]\n",
      "\n",
      "    ...\n",
      "\n",
      "    [[-0.56078434 -0.5529412  -0.9372549 ]\n",
      "     [-0.5372549  -0.5529412  -0.9372549 ]\n",
      "     [-0.5294118  -0.5529412  -0.92941177]\n",
      "     ...\n",
      "     [-0.4509804  -0.5529412  -0.7176471 ]\n",
      "     [-0.48235294 -0.58431375 -0.7411765 ]\n",
      "     [-0.48235294 -0.5764706  -0.7490196 ]]\n",
      "\n",
      "    [[-0.54509807 -0.56078434 -0.92941177]\n",
      "     [-0.5294118  -0.54509807 -0.92941177]\n",
      "     [-0.49019608 -0.52156866 -0.92156863]\n",
      "     ...\n",
      "     [-0.31764707 -0.42745098 -0.60784316]\n",
      "     [-0.34901962 -0.4745098  -0.6313726 ]\n",
      "     [-0.40392157 -0.5294118  -0.6627451 ]]\n",
      "\n",
      "    [[-0.5058824  -0.5137255  -0.9372549 ]\n",
      "     [-0.49803922 -0.49803922 -0.9372549 ]\n",
      "     [-0.5058824  -0.5058824  -0.9372549 ]\n",
      "     ...\n",
      "     [-0.2784314  -0.39607844 -0.56078434]\n",
      "     [-0.3647059  -0.49803922 -0.6156863 ]\n",
      "     [-0.42745098 -0.5529412  -0.6862745 ]]]]]]\n",
      "[1 1 1 1 0 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle Dataset\n",
    "data, labels = unison_shuffled_copies(data, labels)\n",
    "\n",
    "show_amount = 10\n",
    "print(data[:show_amount])\n",
    "print(labels[:show_amount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SPLIT: 0 - 888 | 888 | 80.0%\n",
      "VALIDATION SPLIT: 888 - 999 | 111 | 10.0%\n",
      "TEST SPLIT: 999 - 1110 | 111 | 10.0%\n",
      "---\n",
      "Training Data Shape: (888, 2, 1, 224, 224, 3)\n",
      "Validation Data Shape: (111, 2, 1, 224, 224, 3)\n",
      "Test Data Shape: (111, 2, 1, 224, 224, 3)\n",
      "---\n",
      "Training Labels Shape: (888,)\n",
      "Validation Labels Shape: (111,)\n",
      "Test Labels Shape: (111,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train, validation, and test\n",
    "\n",
    "train_split = int(DATA_TRAIN_SPLIT * len(data))\n",
    "validation_split = train_split+int(DATA_VALIDATION_SPLIT * len(data))\n",
    "\n",
    "print(\"TRAIN SPLIT: \" + \"0 - \" + str(train_split) + \" | \" + str(train_split) + \" | \" + str(DATA_TRAIN_SPLIT*100) + '%')\n",
    "print(\"VALIDATION SPLIT: \" + str(train_split) + \" - \" + str(validation_split) + \" | \" + str(validation_split-train_split) + \" | \" + str(DATA_VALIDATION_SPLIT*100) + '%')\n",
    "print(\"TEST SPLIT: \" + str(validation_split) + \" - \" + str(len(data)) + \" | \" + str(len(data) - validation_split) + \" | \" + str(100 - DATA_TRAIN_SPLIT*100 - DATA_VALIDATION_SPLIT*100) + '%')\n",
    "\n",
    "data_train = data[0:train_split]\n",
    "data_validation = data[train_split:validation_split]\n",
    "data_test = data[validation_split:]\n",
    "\n",
    "labels_train = labels[0:train_split]\n",
    "labels_validation = labels[train_split:validation_split]\n",
    "labels_test = labels[validation_split:]\n",
    "\n",
    "print(\"---\")\n",
    "print(\"Training Data Shape: \" + str(data_train.shape))\n",
    "print(\"Validation Data Shape: \" + str(data_validation.shape))\n",
    "print(\"Test Data Shape: \" + str(data_test.shape))\n",
    "print(\"---\")\n",
    "print(\"Training Labels Shape: \" + str(labels_train.shape))\n",
    "print(\"Validation Labels Shape: \" + str(labels_validation.shape))\n",
    "print(\"Test Labels Shape: \" + str(labels_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input has undefined rank. Received: input_shape=<unknown>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anton\\Documents\\Projects\\semantic-image-similarity\\deep-learning\\contrastive_loss.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/Documents/Projects/semantic-image-similarity/deep-learning/contrastive_loss.ipynb#ch0000008?line=22'>23</a>\u001b[0m x \u001b[39m=\u001b[39m base_model \u001b[39m#.layers[-1].output\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/Documents/Projects/semantic-image-similarity/deep-learning/contrastive_loss.ipynb#ch0000008?line=24'>25</a>\u001b[0m \u001b[39m# input = layers.Input((input_shape))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/Documents/Projects/semantic-image-similarity/deep-learning/contrastive_loss.ipynb#ch0000008?line=25'>26</a>\u001b[0m \u001b[39m# x = tf.keras.layers.BatchNormalization()(input)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/Documents/Projects/semantic-image-similarity/deep-learning/contrastive_loss.ipynb#ch0000008?line=26'>27</a>\u001b[0m \u001b[39m# x = layers.Conv2D(64, (5, 5), activation=\"relu\")(x)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/Documents/Projects/semantic-image-similarity/deep-learning/contrastive_loss.ipynb#ch0000008?line=29'>30</a>\u001b[0m \u001b[39m# x = layers.AveragePooling2D(pool_size=(2, 2))(x)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/Documents/Projects/semantic-image-similarity/deep-learning/contrastive_loss.ipynb#ch0000008?line=30'>31</a>\u001b[0m \u001b[39m# x = layers.Flatten()(x)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/anton/Documents/Projects/semantic-image-similarity/deep-learning/contrastive_loss.ipynb#ch0000008?line=32'>33</a>\u001b[0m x \u001b[39m=\u001b[39m BatchNormalization()(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/Documents/Projects/semantic-image-similarity/deep-learning/contrastive_loss.ipynb#ch0000008?line=33'>34</a>\u001b[0m prediction \u001b[39m=\u001b[39m Dense(\u001b[39m10\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/Documents/Projects/semantic-image-similarity/deep-learning/contrastive_loss.ipynb#ch0000008?line=34'>35</a>\u001b[0m \u001b[39m# embedding_extractor.add(base_model)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/anton/anaconda3/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/anton/anaconda3/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/anton/anaconda3/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/anton/anaconda3/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/anton/anaconda3/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:297\u001b[0m, in \u001b[0;36mBatchNormalizationBase.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/anton/anaconda3/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=294'>295</a>\u001b[0m input_shape \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mTensorShape(input_shape)\n\u001b[0;32m    <a href='file:///c%3A/Users/anton/anaconda3/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=295'>296</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m input_shape\u001b[39m.\u001b[39mndims:\n\u001b[1;32m--> <a href='file:///c%3A/Users/anton/anaconda3/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=296'>297</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/anton/anaconda3/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=297'>298</a>\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput has undefined rank. Received: input_shape=\u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/anton/anaconda3/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=298'>299</a>\u001b[0m ndims \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(input_shape)\n\u001b[0;32m    <a href='file:///c%3A/Users/anton/anaconda3/lib/site-packages/keras/layers/normalization/batch_normalization.py?line=300'>301</a>\u001b[0m \u001b[39m# Convert axis to list and resolve negatives\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Input has undefined rank. Received: input_shape=<unknown>."
     ]
    }
   ],
   "source": [
    "def euclidean_distance_x(vects):\n",
    "    \"\"\"Find the Euclidean distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        vects: List containing two tensors of same length.\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing euclidean distance\n",
    "        (as floating point value) between vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# embedding extractor\n",
    "# embedding_extractor = Sequential(name='embedding_extractor')\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(input_shape), include_top = True, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "x = base_model #.layers[-1].output\n",
    "\n",
    "# input = layers.Input((input_shape))\n",
    "# x = tf.keras.layers.BatchNormalization()(input)\n",
    "# x = layers.Conv2D(64, (5, 5), activation=\"relu\")(x)\n",
    "# x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "# x = layers.Conv2D(32, (5, 5), activation=\"relu\")(x)\n",
    "# x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "# x = layers.Flatten()(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "prediction = Dense(10, activation='sigmoid', dtype='float32')(x)\n",
    "# embedding_extractor.add(base_model)\n",
    "\n",
    "embedding_extractor = Model(inputs=input, outputs=prediction, name='embedding_extractor')\n",
    "\n",
    "# embedding_extractor.add(base_model)\n",
    "# embedding_extractor.add(GlobalAveragePooling2D())\n",
    "# embedding_extractor.add(Flatten())\n",
    "\n",
    "embedding_extractor.summary()\n",
    "\n",
    "# Input pair\n",
    "input_image_1 = Input(input_shape)\n",
    "input_image_2 = Input(input_shape)\n",
    "\n",
    "# Output pair\n",
    "encoded_image_1 = embedding_extractor(input_image_1)\n",
    "encoded_image_2 = embedding_extractor(input_image_2)\n",
    "\n",
    "merge_layer = Lambda(euclidean_distance_x)([encoded_image_1, encoded_image_2])\n",
    "normal_layer = BatchNormalization()(merge_layer)\n",
    "output_layer = Dense(1, activation='sigmoid', dtype='float32')(normal_layer)\n",
    "siamese = Model(inputs=[input_image_1, input_image_2], outputs=output_layer, name='siamese')\n",
    "\n",
    "# # Model\n",
    "# feature_extraction_model = Model(inputs=[input_image_1, input_image_2], outputs=[encoded_image_1, encoded_image_2], name='feature_extractor')\n",
    "# feature_extraction_model.summary()\n",
    "\n",
    "def loss(margin=1):\n",
    "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
    "\n",
    "  Arguments:\n",
    "      margin: Integer, defines the baseline for distance for which pairs\n",
    "              should be classified as dissimilar. - (default is 1).\n",
    "\n",
    "  Returns:\n",
    "      'constrastive_loss' function with data ('margin') attached.\n",
    "  \"\"\"\n",
    "\n",
    "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
    "    #                         true_value * square( max(margin-prediction, 0) ))\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        \"\"\"Calculates the constrastive loss.\n",
    "\n",
    "      Arguments:\n",
    "          y_true: List of labels, each label is of type float32.\n",
    "          y_pred: List of predictions of same length as of y_true,\n",
    "                  each label is of type float32.\n",
    "\n",
    "      Returns:\n",
    "          A tensor containing constrastive loss as floating point value.\n",
    "      \"\"\"\n",
    "\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss\n",
    "\n",
    "siamese.compile(loss=loss(margin=1), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "28/28 [==============================] - 76s 3s/step - loss: 0.3194 - accuracy: 0.4899 - val_loss: 0.3272 - val_accuracy: 0.5405\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.2871 - accuracy: 0.5214 - val_loss: 0.3113 - val_accuracy: 0.5045\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.2759 - accuracy: 0.5394 - val_loss: 0.3335 - val_accuracy: 0.4595\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.2660 - accuracy: 0.5574 - val_loss: 0.3269 - val_accuracy: 0.5315\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 74s 3s/step - loss: 0.2542 - accuracy: 0.5957 - val_loss: 0.3237 - val_accuracy: 0.4685\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.2363 - accuracy: 0.6306 - val_loss: 0.3554 - val_accuracy: 0.5495\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.2185 - accuracy: 0.6824 - val_loss: 0.3559 - val_accuracy: 0.4414\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.1998 - accuracy: 0.7196 - val_loss: 0.3259 - val_accuracy: 0.4685\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.1799 - accuracy: 0.7511 - val_loss: 0.3394 - val_accuracy: 0.4234\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.1646 - accuracy: 0.7703 - val_loss: 0.3930 - val_accuracy: 0.4685\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 76s 3s/step - loss: 0.1487 - accuracy: 0.8187 - val_loss: 0.3693 - val_accuracy: 0.4234\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.1467 - accuracy: 0.8232 - val_loss: 0.3972 - val_accuracy: 0.4414\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 76s 3s/step - loss: 0.1294 - accuracy: 0.8525 - val_loss: 0.3768 - val_accuracy: 0.4054\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 76s 3s/step - loss: 0.1210 - accuracy: 0.8773 - val_loss: 0.4354 - val_accuracy: 0.4234\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.1122 - accuracy: 0.8885 - val_loss: 0.3965 - val_accuracy: 0.4414\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 76s 3s/step - loss: 0.0991 - accuracy: 0.9133 - val_loss: 0.3884 - val_accuracy: 0.4324\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.0890 - accuracy: 0.9189 - val_loss: 0.3588 - val_accuracy: 0.4595\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.0912 - accuracy: 0.9065 - val_loss: 0.4109 - val_accuracy: 0.4234\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 75s 3s/step - loss: 0.0789 - accuracy: 0.9381 - val_loss: 0.4386 - val_accuracy: 0.3874\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 76s 3s/step - loss: 0.0746 - accuracy: 0.9358 - val_loss: 0.4590 - val_accuracy: 0.4234\n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "history = siamese.fit(\n",
    "    [data_train[:, 0, 0], data_train[:, 1, 0]],\n",
    "    labels_train.astype(float),\n",
    "    validation_data=([data_validation[:, 0, 0], data_validation[:, 1, 0]], labels_validation),\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tfig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\tax[0].set_title('Cross Entropy Loss')\n",
    "\tax[0].set_xlabel('Epoch')\n",
    "\tax[0].set_ylabel('Loss')\n",
    "\tax[0].plot(history.history['loss'], color='blue', label='train')\n",
    "\tax[0].plot(history.history['val_loss'], color='orange', label='validation')\n",
    "\tax[0].legend()\n",
    "\n",
    "\t# plot accuracy\n",
    "\tax[1].set_title('Classification Accuracy')\n",
    "\tax[1].set_xlabel('Epoch')\n",
    "\tax[1].set_ylabel('Accuracy')\n",
    "\tax[1].plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tax[1].plot(history.history['val_accuracy'], color='orange', label='validation')\n",
    "\tax[1].legend()\n",
    "\t\n",
    "\tplt.show()\n",
    "\n",
    "summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4339057207107544\n",
      "Test accuracy: 0.46846845746040344\n"
     ]
    }
   ],
   "source": [
    "score = siamese.evaluate(\n",
    "    [data_test[:, 0, 0], data_test[:, 1, 0]], \n",
    "    labels_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a4880536bc750f262d1b458e4fd4d611315d3098d58b77bd9c89b3237b9ab47"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
